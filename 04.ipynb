{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89813c6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%markdown\n",
    "# INFO-F-422 - Statistical Foundations of Machine Learning\n",
    "\n",
    "### Python version of the \"Predictions: Network-based methods\" tutorial\n",
    "\n",
    "This tutorial demonstrates how to perform regression with neural networks using Python and TensorFlow/Keras. It follows a similar structure and logic as the provided R tutorial, using the [Auto MPG dataset](https://archive.ics.uci.edu/ml/datasets/auto+mpg).\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "- Load and preprocess the data\n",
    "- Normalize the features\n",
    "- Build linear and DNN (deep neural network) regression models\n",
    "- Evaluate the models and visualize their performance\n",
    "\n",
    "We will use TensorFlow, Keras, and other Python libraries for data handling and plotting.\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce5d2c",
   "metadata": {},
   "source": [
    "!pip install tensorflow pandas numpy matplotlib seaborn sklearn\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "```\n",
    "\n",
    "## The Auto MPG dataset\n",
    "\n",
    "We use the Auto MPG dataset. The goal is to predict the fuel efficiency (miles per gallon, MPG) of a car from its characteristics.\n",
    "\n",
    "**Data description:**\n",
    "- mpg: Miles per gallon (target variable)\n",
    "- cylinders\n",
    "- displacement\n",
    "- horsepower\n",
    "- weight\n",
    "- acceleration\n",
    "- model_year\n",
    "- origin\n",
    "- car_name\n",
    "\n",
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "column_names = [\"mpg\",\"cylinders\",\"displacement\",\"horsepower\",\"weight\",\"acceleration\",\"model_year\",\"origin\",\"car_name\"]\n",
    "\n",
    "raw_dataset = pd.read_csv(url, names=column_names,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True)\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c10af38",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2dec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# The 'origin' column is categorical, so we convert it to one-hot encoding\n",
    "dataset[\"origin\"] = dataset[\"origin\"].replace({1:\"USA\", 2:\"Europe\", 3:\"Japan\"})\n",
    "dataset = pd.get_dummies(dataset, columns=[\"origin\"], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "dataset = dataset.drop(\"car_name\", axis=1)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d57c0d",
   "metadata": {},
   "source": [
    "## Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_features = train_dataset.drop(\"mpg\", axis=1)\n",
    "test_features = test_dataset.drop(\"mpg\", axis=1)\n",
    "\n",
    "train_labels = train_dataset[\"mpg\"]\n",
    "test_labels = test_dataset[\"mpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabf876",
   "metadata": {},
   "source": [
    "## Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e3eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d8bc81",
   "metadata": {},
   "source": [
    "We see different scales for different features. Normalization is important.\n",
    "\n",
    "## Normalization\n",
    "\n",
    "We'll use a `tf.keras.layers.Normalization` layer to normalize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583705a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f257f",
   "metadata": {},
   "source": [
    "When we call the normalizer on the data, it will normalize each feature to have mean 0 and variance 1.\n",
    "\n",
    "## Linear regression with a single input (Horsepower)\n",
    "\n",
    "Let's first build a simple linear regression model that predicts `mpg` from the `horsepower` feature alone.\n",
    "\n",
    "We will:\n",
    "1. Extract the `horsepower` feature.\n",
    "2. Create a `Normalization` layer for just this feature.\n",
    "3. Build a linear model `mpg = w * horsepower + b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fa96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower = np.array(train_features[\"horsepower\"])\n",
    "horsepower_normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
    "horsepower_normalizer.adapt(horsepower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342cff37",
   "metadata": {},
   "source": [
    "### Single-variable linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f6076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower_model = keras.Sequential([\n",
    "    horsepower_normalizer,\n",
    "    layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "horsepower_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error'\n",
    ")\n",
    "\n",
    "history = horsepower_model.fit(\n",
    "    train_features[\"horsepower\"], train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814d496",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Plot training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb134e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [MPG]')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6c1c2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Evaluate on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "test_results['horsepower_model'] = horsepower_model.evaluate(\n",
    "    test_features[\"horsepower\"], test_labels, verbose=0)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2671a6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Visualize predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(0.0, 250, 251)\n",
    "y = horsepower_model.predict(x)\n",
    "\n",
    "plt.scatter(train_features[\"horsepower\"], train_labels, label='Data')\n",
    "plt.plot(x, y, color='red', label='Prediction')\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('MPG')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a9a90",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Linear regression with multiple inputs\n",
    "\n",
    "Use all features in a linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bfa295",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "linear_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error'\n",
    ")\n",
    "\n",
    "history = linear_model.fit(\n",
    "    train_features, train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    epochs=100\n",
    ")\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [MPG]')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "test_results['linear_model'] = linear_model.evaluate(\n",
    "    test_features, test_labels, verbose=0)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260b43f",
   "metadata": {},
   "source": [
    "## Deep Neural Network (DNN) regression\n",
    "\n",
    "We now build a deeper model with hidden layers to better capture nonlinearities.\n",
    "\n",
    "### Single input DNN (Horsepower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd08922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm_layer):\n",
    "    model = keras.Sequential([\n",
    "        norm_layer,\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=keras.optimizers.Adam(0.001))\n",
    "    return model\n",
    "\n",
    "dnn_horsepower_model = build_and_compile_model(horsepower_normalizer)\n",
    "\n",
    "history = dnn_horsepower_model.fit(\n",
    "    train_features[\"horsepower\"], train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100\n",
    ")\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [MPG]')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "test_results['dnn_horsepower_model'] = dnn_horsepower_model.evaluate(\n",
    "    test_features[\"horsepower\"], test_labels, verbose=0)\n",
    "\n",
    "x = tf.linspace(0.0, 250, 251)\n",
    "y = dnn_horsepower_model.predict(x)\n",
    "\n",
    "plt.scatter(train_features[\"horsepower\"], train_labels, label='Data')\n",
    "plt.plot(x, y, color='red', label='Prediction')\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('MPG')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233be367",
   "metadata": {},
   "source": [
    "### DNN with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)\n",
    "\n",
    "history = dnn_model.fit(\n",
    "    train_features, train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100\n",
    ")\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [MPG]')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f63e85",
   "metadata": {},
   "source": [
    "## Evaluate and compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c937f18",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Check prediction performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9865ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.plot([0,50],[0,50], 'r')\n",
    "plt.show()\n",
    "\n",
    "error = test_predictions - test_labels\n",
    "sns.kdeplot(error, shade=True)\n",
    "plt.xlabel('Prediction Error [MPG]')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45154f",
   "metadata": {},
   "source": [
    "## Save and reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e824235",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.save('dnn_model')\n",
    "reloaded = keras.models.load_model('dnn_model')\n",
    "\n",
    "test_results['reloaded'] = reloaded.evaluate(test_features, test_labels, verbose=0)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6f6d7",
   "metadata": {},
   "source": [
    "We see that the reloaded model performs identically.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "- We explored linear and DNN models for regression.\n",
    "- With proper normalization and a deeper architecture, the DNN model achieved better performance.\n",
    "- We examined the loss, visualized predictions, and error distributions.\n",
    "- We saved and reloaded the model.\n",
    "\n",
    "You now have a foundation for performing regression tasks with neural networks in Python using TensorFlow/Keras.\n",
    "```\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
